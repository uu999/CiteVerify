# -*- coding: utf-8 -*-
"""
ç«¯åˆ°ç«¯æµ‹è¯•ï¼šPDF URL -> æå–å‚è€ƒæ–‡çŒ® -> æ ¡éªŒçœŸä¼ª -> ç”ŸæˆæŠ¥å‘Š

å®Œæ•´æµç¨‹ï¼š
1. è¾“å…¥è®ºæ–‡ PDF URL
2. è½¬æ¢ä¸º Markdown
3. æå–å‚è€ƒæ–‡çŒ®åˆ—è¡¨
4. é€æ¡æ ¡éªŒçœŸä¼ªï¼ˆarXiv -> Semantic Scholar -> OpenAlexï¼‰
5. ç”Ÿæˆæ ¡éªŒæŠ¥å‘Š
"""
import sys
import json
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Any, Optional

project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root / "src"))

from citeverify.pipeline import extract_references_from_url
from citeverify.checkers import verify_references, SearchSource
from citeverify.models import YaYiDocParserConfig

# Semantic Scholar API Keyï¼ˆå¯è®¾ä¸ºç¯å¢ƒå˜é‡æˆ–ç›´æ¥å¡«å†™ï¼‰
DEFAULT_SS_API_KEY = "k2PL5V0UK25YRzHgin5F18R06qyyuH662LOxywaV"


def verify_paper_references(
    pdf_url: str,
    citation_format: str = "ieee",
    listing_style: str = "numbered",
    output_dir: str = "output",
    request_delay: float = 1.5,
    semantic_scholar_api_key: Optional[str] = None,
    use_semantic_scholar: bool = True,
    use_openalex: bool = True,
    save_report: bool = True,
) -> Dict[str, Any]:
    """
    ä» PDF URL æå–å‚è€ƒæ–‡çŒ®å¹¶æ ¡éªŒçœŸä¼ª
    
    æœç´¢ä¼˜å…ˆçº§ï¼šarXiv -> Semantic Scholar -> OpenAlex
    
    Args:
        pdf_url: è®ºæ–‡ PDF çš„ URL
        citation_format: å¼•ç”¨æ ¼å¼ï¼ˆapa, mla, ieee, gb_t_7714, chicago, harvard, vancouverï¼‰
        listing_style: åˆ—ä¸¾æ–¹å¼ï¼ˆnumbered æˆ– author_yearï¼‰
        output_dir: è¾“å‡ºç›®å½•
        request_delay: API è¯·æ±‚é—´éš”ï¼ˆç§’ï¼‰
        semantic_scholar_api_key: Semantic Scholar API Key
        use_semantic_scholar: æ˜¯å¦ä½¿ç”¨ Semantic Scholar
        use_openalex: æ˜¯å¦ä½¿ç”¨ OpenAlex
        save_report: æ˜¯å¦ä¿å­˜æŠ¥å‘Šæ–‡ä»¶
        
    Returns:
        æ ¡éªŒæŠ¥å‘Šå­—å…¸
    """
    # ä½¿ç”¨é»˜è®¤ API Keyï¼ˆå¦‚æœæœªæä¾›ï¼‰
    if semantic_scholar_api_key is None:
        semantic_scholar_api_key = DEFAULT_SS_API_KEY
    print("=" * 70)
    print("å‚è€ƒæ–‡çŒ®çœŸä¼ªæ ¡éªŒç³»ç»Ÿ")
    print("=" * 70)
    print(f"è®ºæ–‡ URL: {pdf_url}")
    print(f"å¼•ç”¨æ ¼å¼: {citation_format}")
    print(f"åˆ—ä¸¾æ–¹å¼: {listing_style}")
    print("-" * 70)
    
    # 1. æå–å‚è€ƒæ–‡çŒ®
    print("\nğŸ“„ Step 1: æå–å‚è€ƒæ–‡çŒ®...")
    
    yayi_config = YaYiDocParserConfig()
    
    extraction_result = extract_references_from_url(
        pdf_url,
        citation_format=citation_format,
        listing_style=listing_style,
        yayi_config=yayi_config,
        download_timeout=600,
    )
    
    if not extraction_result.success:
        print(f"âŒ æå–å¤±è´¥: {extraction_result.error}")
        return {"success": False, "error": extraction_result.error}
    
    references = extraction_result.references
    print(f"âœ… æå–å®Œæˆï¼Œå…± {len(references)} æ¡å‚è€ƒæ–‡çŒ®")
    
    if not references:
        print("âš ï¸ æœªæå–åˆ°å‚è€ƒæ–‡çŒ®")
        return {"success": False, "error": "æœªæå–åˆ°å‚è€ƒæ–‡çŒ®"}
    
    # 2. æ ¡éªŒå‚è€ƒæ–‡çŒ®
    sources = ["arXiv"]
    if use_semantic_scholar:
        sources.append("Semantic Scholar")
    if use_openalex:
        sources.append("OpenAlex")
    print(f"\nğŸ” Step 2: æ ¡éªŒå‚è€ƒæ–‡çŒ®çœŸä¼ªï¼ˆä½¿ç”¨ {' -> '.join(sources)}ï¼‰...")
    print(f"   è¯·æ±‚é—´éš”: {request_delay}s")
    print("-" * 70)
    
    has_number = (listing_style == "numbered")
    
    verified_refs = verify_references(
        references,
        has_number=has_number,
        request_delay=request_delay,
        semantic_scholar_api_key=semantic_scholar_api_key,
        use_semantic_scholar=use_semantic_scholar,
        use_openalex=use_openalex,
        verbose=True,
    )
    
    # 3. ç”ŸæˆæŠ¥å‘Š
    print(f"\nğŸ“Š Step 3: ç”Ÿæˆæ ¡éªŒæŠ¥å‘Š...")
    
    report = generate_report(
        pdf_url=pdf_url,
        verified_refs=verified_refs,
        has_number=has_number,
        citation_format=citation_format,
    )
    
    # 4. æ‰“å°æŠ¥å‘Š
    print_report(report)
    
    # 5. ä¿å­˜æŠ¥å‘Š
    if save_report:
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        # ä» URL æå–æ–‡ä»¶å
        url_name = pdf_url.split("/")[-1].split("?")[0]
        if url_name.endswith(".pdf"):
            url_name = url_name[:-4]
        report_name = f"verification_report_{url_name[:30]}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        report_file = output_path / report_name
        with open(report_file, "w", encoding="utf-8") as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ’¾ æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
    
    return report


def generate_report(
    pdf_url: str,
    verified_refs: List[List],
    has_number: bool,
    citation_format: str,
) -> Dict[str, Any]:
    """
    ç”Ÿæˆæ ¡éªŒæŠ¥å‘Š
    
    Args:
        pdf_url: è®ºæ–‡ URL
        verified_refs: æ ¡éªŒåçš„å‚è€ƒæ–‡çŒ®åˆ—è¡¨
        has_number: æ˜¯å¦æœ‰ç¼–å·
        citation_format: å¼•ç”¨æ ¼å¼
        
    Returns:
        æŠ¥å‘Šå­—å…¸
    """
    total = len(verified_refs)
    verified_count = sum(1 for r in verified_refs if r[-3])  # can_get å­—æ®µ
    unverified_count = total - verified_count
    
    # æŒ‰æ¥æºç»Ÿè®¡ï¼ˆé€šè¿‡ URL ç‰¹å¾åˆ¤æ–­ï¼‰
    arxiv_count = 0
    ss_count = 0
    openalex_count = 0
    has_pdf_count = 0
    
    details = []
    
    for i, ref in enumerate(verified_refs):
        if has_number:
            # [ç¼–å·, å…¨æ–‡, æ ‡é¢˜, ä½œè€…, å¹´ä»½, can_get, abstract, pdf_url, source]
            num = ref[0]
            title = ref[2]
            authors = ref[3]
            year = ref[4]
            can_get = ref[-4]
            abstract = ref[-3]
            pdf_url_ref = ref[-2]
            source = ref[-1]
        else:
            # [å…¨æ–‡, æ ‡é¢˜, ä½œè€…, å¹´ä»½, can_get, abstract, pdf_url, source]
            num = i + 1
            title = ref[1]
            authors = ref[2]
            year = ref[3]
            can_get = ref[-4]
            abstract = ref[-3]
            pdf_url_ref = ref[-2]
            source = ref[-1]
        
        detail = {
            "number": num,
            "title": title,
            "authors": authors,
            "year": year,
            "verified": can_get,
            "has_pdf": bool(pdf_url_ref),
            "pdf_url": pdf_url_ref,
            "source": source,
            "abstract_preview": abstract[:200] + "..." if abstract and len(abstract) > 200 else abstract,
        }
        details.append(detail)
        
        if can_get:
            if pdf_url_ref:
                has_pdf_count += 1
            # ä½¿ç”¨å®é™…æ¥æºå­—æ®µç»Ÿè®¡
            if source == "arxiv":
                arxiv_count += 1
            elif source == "semantic_scholar":
                ss_count += 1
            elif source == "openalex":
                openalex_count += 1
    
    report = {
        "meta": {
            "pdf_url": pdf_url,
            "citation_format": citation_format,
            "has_number": has_number,
            "generated_at": datetime.now().isoformat(),
        },
        "summary": {
            "total": total,
            "verified": verified_count,
            "unverified": unverified_count,
            "verification_rate": f"{verified_count / total * 100:.1f}%" if total > 0 else "N/A",
            "arxiv_found": arxiv_count,
            "semantic_scholar_found": ss_count,
            "openalex_found": openalex_count,
            "has_pdf": has_pdf_count,
        },
        "details": details,
    }
    
    return report


def print_report(report: Dict[str, Any]) -> None:
    """æ‰“å°æ ¡éªŒæŠ¥å‘Š"""
    summary = report["summary"]
    details = report["details"]
    
    print("\n" + "=" * 70)
    print("ğŸ“‹ æ ¡éªŒæŠ¥å‘Š")
    print("=" * 70)
    
    print(f"\nğŸ“Š ç»Ÿè®¡æ‘˜è¦:")
    print(f"   æ€»å‚è€ƒæ–‡çŒ®æ•°:     {summary['total']}")
    print(f"   âœ… å¯éªŒè¯:        {summary['verified']} ({summary['verification_rate']})")
    print(f"   âŒ æ— æ³•éªŒè¯:      {summary['unverified']}")
    print(f"   ğŸ“š æ¥è‡ª arXiv:    {summary['arxiv_found']}")
    print(f"   ğŸ“– æ¥è‡ª Semantic Scholar: {summary['semantic_scholar_found']}")
    print(f"   ğŸ”¬ æ¥è‡ª OpenAlex: {summary.get('openalex_found', 0)}")
    print(f"   ğŸ“„ æœ‰ PDF é“¾æ¥:   {summary['has_pdf']}")
    
    print(f"\nğŸ“ è¯¦ç»†ç»“æœ:")
    print("-" * 70)
    
    for d in details:
        status = "âœ…" if d["verified"] else "âŒ"
        pdf_status = "ğŸ“„" if d["has_pdf"] else "  "
        title_display = d["title"][:50] + "..." if d["title"] and len(d["title"]) > 50 else (d["title"] or "(æ— æ ‡é¢˜)")
        
        print(f"  [{d['number']:2}] {status} {pdf_status} {title_display}")
        if d["verified"] and d["pdf_url"]:
            print(f"       â””â”€ PDF: {d['pdf_url'][:60]}...")
    
    print("\n" + "=" * 70)
    
    # åˆ—å‡ºæ— æ³•éªŒè¯çš„æ–‡çŒ®
    unverified = [d for d in details if not d["verified"]]
    if unverified:
        print("\nâš ï¸ æ— æ³•éªŒè¯çš„æ–‡çŒ®ï¼ˆå¯èƒ½éœ€è¦äººå·¥æ ¸å®ï¼‰:")
        for d in unverified:
            title = d["title"] if d["title"] else "(æ— æ ‡é¢˜)"
            print(f"   [{d['number']}] {title}")
    
    print("=" * 70)


if __name__ == "__main__":
    import argparse
    import os
    
    parser = argparse.ArgumentParser(
        description="ä»è®ºæ–‡ PDF æå–å‚è€ƒæ–‡çŒ®å¹¶æ ¡éªŒçœŸä¼ªï¼ˆarXiv -> Semantic Scholar -> OpenAlexï¼‰"
    )
    parser.add_argument("pdf_url", help="è®ºæ–‡ PDF çš„ URL")
    parser.add_argument(
        "-c", "--citation-format",
        choices=["apa", "mla", "ieee", "gb_t_7714", "chicago", "harvard", "vancouver"],
        default="ieee",
        help="å¼•ç”¨æ ¼å¼ (é»˜è®¤: ieee)"
    )
    parser.add_argument(
        "-l", "--listing-style",
        choices=["numbered", "author_year"],
        default="numbered",
        help="åˆ—ä¸¾æ–¹å¼ (é»˜è®¤: numbered)"
    )
    parser.add_argument(
        "-o", "--output-dir",
        default="output",
        help="è¾“å‡ºç›®å½• (é»˜è®¤: output)"
    )
    parser.add_argument(
        "-d", "--delay",
        type=float,
        default=1.5,
        help="API è¯·æ±‚é—´éš”ç§’æ•° (é»˜è®¤: 1.5)"
    )
    parser.add_argument(
        "--ss-api-key",
        default=None,
        help="Semantic Scholar API Keyï¼ˆé»˜è®¤ä½¿ç”¨å†…ç½® Keyï¼‰"
    )
    parser.add_argument(
        "--no-semantic-scholar",
        action="store_true",
        help="ç¦ç”¨ Semantic Scholar"
    )
    parser.add_argument(
        "--no-openalex",
        action="store_true",
        help="ç¦ç”¨ OpenAlex"
    )
    parser.add_argument(
        "--no-save",
        action="store_true",
        help="ä¸ä¿å­˜æŠ¥å‘Šæ–‡ä»¶"
    )
    
    args = parser.parse_args()
    
    # è·å– API Keyï¼ˆä¼˜å…ˆå‘½ä»¤è¡Œå‚æ•°ï¼Œå…¶æ¬¡ç¯å¢ƒå˜é‡ï¼Œæœ€åé»˜è®¤å€¼ï¼‰
    ss_api_key = args.ss_api_key or os.environ.get("SEMANTIC_SCHOLAR_API_KEY") or DEFAULT_SS_API_KEY
    
    verify_paper_references(
        pdf_url=args.pdf_url,
        citation_format=args.citation_format,
        listing_style=args.listing_style,
        output_dir=args.output_dir,
        request_delay=args.delay,
        semantic_scholar_api_key=ss_api_key,
        use_semantic_scholar=not args.no_semantic_scholar,
        use_openalex=not args.no_openalex,
        save_report=not args.no_save,
    )
