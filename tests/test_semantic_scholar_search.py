# -*- coding: utf-8 -*-
"""
æµ‹è¯• Semantic Scholar æœç´¢èƒ½åŠ›

éªŒè¯ Semantic Scholar API å¯¹äºç»™å®šå‚è€ƒæ–‡çŒ®æ ‡é¢˜çš„æœç´¢å’ŒåŒ¹é…æƒ…å†µã€‚
ç”¨äºè¯Šæ–­ï¼šæ˜¯æœä¸åˆ°è¿˜æ˜¯åŒ¹é…å¤ªä¸¥æ ¼ï¼Ÿ

æ–°å¢ï¼šåŒ…å«åŸå§‹ OCR/æå–é”™è¯¯çš„æ ‡é¢˜ï¼ˆä¸çº æ­£ï¼‰
"""
import sys
import time
from pathlib import Path

project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root / "src"))

from citeverify.checkers import ReferenceChecker

# Semantic Scholar API Key
SS_API_KEY = "k2PL5V0UK25YRzHgin5F18R06qyyuH662LOxywaV"

# åŸå§‹æµ‹è¯•ç”¨ä¾‹ï¼ˆ20ç¯‡ï¼‰
ORIGINAL_TEST_REFERENCES = [
    {
        "num": 2,
        "title": "Potential Pitfalls of Process Modeling: Part A",
        "year": "2006",
        "authors": "M. Rosemann",
    },
    {
        "num": 3,
        "title": "Opportunities and Constraints: The Current Struggle with BPMN",
        "year": "2010",
        "authors": "J. Recker",
    },
    {
        "num": 4,
        "title": "IT-Business Alignment: A Systematic Literature Review",
        "year": "2021",
        "authors": "S. Q. Njanka, G. Sandula, R. Colomo-Palacios",
    },
    # ... å…¶ä»–åŸå§‹æ¡ç›®ä¿æŒä¸å˜ï¼ˆæ­¤å¤„çœç•¥ä»¥èŠ‚çœç©ºé—´ï¼‰
    {
        "num": 20,
        "title": "Introducing the BPMN-Chatbot for Efficient LLM-Based Process Modeling",
        "year": "2024",
        "authors": "J. KÃ¶pke, A. Safan",
    },
]

# ğŸ”¥ æ–°å¢ï¼šä»ç”¨æˆ·è¾“å…¥ä¸­æå–çš„â€œå¸¦é”™è¯¯â€çš„æ ‡é¢˜ï¼ˆä¸çº æ­£ï¼ï¼‰
NOISY_TITLES_FROM_USER = [
    "IT-Business Alignment:ASvstematic Literature Review",
    "Disentangling Organizational Agility from Flexibility,Adaptability,and Versatility: A Systematic Review",
    "Process Mining:A Research Agenda",
    "Leveraging Large Language Models (LLMs)for Process Mining (Technical Report",
    "Automated Generation of BPMN Processes from Textual Requirements",
    "GPT-4oSystem Card",
    "The Llama 3 Herd ofModels",
    "DeepSeek-V3 TechnicalReport",
    "Similarity of Business Process Modelsâ€”A State-of-the-Art Analysis",
    "TheBusiness Process Model Quality Metrics"
]

# æ„å»ºæ–°å¢æµ‹è¯•ç”¨ä¾‹ï¼ˆç¼–å·ä» 100 å¼€å§‹ï¼Œé¿å…å†²çªï¼‰
NOISY_TEST_REFERENCES = []
for i, title in enumerate(NOISY_TITLES_FROM_USER, start=100):
    NOISY_TEST_REFERENCES.append({
        "num": i,
        "title": title,
        "year": None,  # ç”¨æˆ·æœªæä¾›å¹´ä»½ï¼Œè®¾ä¸º None
        "authors": "(Unknown)"
    })

# åˆå¹¶æµ‹è¯•é›†
TEST_REFERENCES = ORIGINAL_TEST_REFERENCES + NOISY_TEST_REFERENCES


def test_semantic_scholar_raw_search():
    """
    æµ‹è¯•åŸå§‹ Semantic Scholar API æœç´¢ï¼ˆä¸ç»è¿‡åŒ¹é…é€»è¾‘ï¼‰

    ç›®çš„ï¼šåŒºåˆ†æ˜¯ API æœä¸åˆ°è¿˜æ˜¯åŒ¹é…é€»è¾‘å¤ªä¸¥æ ¼
    """
    import requests

    print("=" * 80)
    print("Semantic Scholar åŸå§‹æœç´¢æµ‹è¯•ï¼ˆä¸ç»è¿‡åŒ¹é…é€»è¾‘ï¼‰")
    print("=" * 80)
    print(f"ä½¿ç”¨ API Key: {SS_API_KEY[:10]}...")
    print(f"å…± {len(TEST_REFERENCES)} ç¯‡æ–‡çŒ®å¾…æµ‹è¯•ï¼ˆå«åŸå§‹+å™ªå£°æ ‡é¢˜ï¼‰")
    print("-" * 80)

    api_url = "https://api.semanticscholar.org/graph/v1/paper/search"
    headers = {"x-api-key": SS_API_KEY}

    results_summary = {
        "api_found": 0,
        "api_not_found": 0,
        "api_error": 0,
    }

    for ref in TEST_REFERENCES:
        title = ref["title"]
        year = ref["year"]
        num = ref["num"]

        print(f"\n[{num}] æœç´¢: {title[:60]}{'...' if len(title) > 60 else ''}")
        if year:
            print(f"    å¹´ä»½: {year}")

        # æ³¨æ„ï¼šè¿™é‡Œä¾ç„¶ç”¨åŸå§‹æ ‡é¢˜ï¼ˆå«é”™è¯¯ï¼‰è¿›è¡ŒæŸ¥è¯¢
        params = {
            "query": f'"{title}"',  # å°è¯•ç²¾ç¡®çŸ­è¯­æœç´¢
            "limit": 20,
            "fields": "title,year",
        }
        if year:
            params["year"] = year

        time.sleep(1.1)  # éµå®ˆé™æµ

        try:
            response = requests.get(api_url, params=params, headers=headers, timeout=30)

            if response.status_code == 429:
                print(f"    âš ï¸ é™æµ 429ï¼Œç­‰å¾…åé‡è¯•...")
                time.sleep(5)
                response = requests.get(api_url, params=params, headers=headers, timeout=30)

            if response.status_code != 200:
                print(f"    âŒ API é”™è¯¯: {response.status_code}")
                results_summary["api_error"] += 1
                continue

            data = response.json()
            papers = data.get("data", [])
            total = data.get("total", 0)

            if papers:
                results_summary["api_found"] += 1
                print(f"    âœ… API è¿”å› {len(papers)} æ¡ç»“æœï¼ˆæ€»å…± {total} æ¡ï¼‰")

                # ä½¿ç”¨å®é™…çš„åŒ¹é…é€»è¾‘
                from citeverify.checkers import ReferenceChecker
                
                for i, paper in enumerate(papers[:3]):
                    p_title = paper.get("title", "")
                    p_year = paper.get("year", "")

                    # ä½¿ç”¨æ–°çš„åŒ¹é…é€»è¾‘
                    is_match, similarity = ReferenceChecker.titles_match(title, p_title)
                    
                    if similarity >= 1.0:
                        match_status = "ğŸ¯ç²¾ç¡®"
                    elif is_match:
                        match_status = f"âœ…åŒ¹é…({similarity:.2f})"
                    else:
                        match_status = f"âŒ({similarity:.2f})"
                    
                    print(
                        f"       [{i + 1}] {match_status} | {p_title[:50]}{'...' if len(p_title) > 50 else ''} ({p_year})")
            else:
                results_summary["api_not_found"] += 1
                print(f"    âŒ API æ— ç»“æœ")

                # å°è¯•å»æ‰å¼•å·ï¼ˆæ¨¡ç³Šæœç´¢ï¼‰
                params_fuzzy = {"query": title, "limit": 5, "fields": "title,year"}
                if year:
                    params_fuzzy["year"] = year
                time.sleep(1.1)
                response2 = requests.get(api_url, params=params_fuzzy, headers=headers, timeout=30)
                if response2.status_code == 200:
                    data2 = response2.json()
                    papers2 = data2.get("data", [])
                    if papers2:
                        print(f"       ğŸ’¡ æ¨¡ç³Šæœç´¢æ‰¾åˆ° {len(papers2)} æ¡ç»“æœ:")
                        for p in papers2[:2]:
                            print(f"          - {p.get('title', '')[:50]} ({p.get('year', '')})")

        except Exception as e:
            print(f"    âŒ è¯·æ±‚å¼‚å¸¸: {e}")
            results_summary["api_error"] += 1

    print("\n" + "=" * 80)
    print("æµ‹è¯•æ€»ç»“")
    print("=" * 80)
    total = len(TEST_REFERENCES)
    print(f"æ€»æµ‹è¯•æ•°:       {total}")
    print(f"âœ… API æœ‰ç»“æœ:  {results_summary['api_found']} ({results_summary['api_found'] / total * 100:.1f}%)")
    print(f"âŒ API æ— ç»“æœ:  {results_summary['api_not_found']} ({results_summary['api_not_found'] / total * 100:.1f}%)")
    print(f"âš ï¸ API é”™è¯¯:    {results_summary['api_error']}")
    print("=" * 80)


def test_full_checker():
    """
    æµ‹è¯•å®Œæ•´çš„ ReferenceCheckerï¼ˆåŒ…å«åŒ¹é…é€»è¾‘ï¼‰
    """
    print("\n" + "=" * 80)
    print("ReferenceChecker å®Œæ•´æµ‹è¯•ï¼ˆåŒ…å«åŒ¹é…é€»è¾‘ï¼‰")
    print("=" * 80)

    checker = ReferenceChecker(
        request_delay=1.5,
        semantic_scholar_api_key=SS_API_KEY,
        use_semantic_scholar=True,
        use_openalex=True,
    )

    results_summary = {
        "found": 0,
        "not_found": 0,
        "by_source": {
            "arxiv": 0,
            "semantic_scholar": 0,
            "openalex": 0,
        }
    }

    for ref in TEST_REFERENCES:
        title = ref["title"]
        year = ref["year"]
        num = ref["num"]

        print(f"\n[{num}] æ ¡éªŒ: {title[:50]}{'...' if len(title) > 50 else ''}")

        result = checker.verify_reference(title, year=year)

        if result.can_get:
            results_summary["found"] += 1
            source = result.source.value
            results_summary["by_source"][source] = results_summary["by_source"].get(source, 0) + 1

            print(f"    âœ… æ‰¾åˆ° | æ¥æº: {source} | ç›¸ä¼¼åº¦: {result.similarity:.2f}")
            print(f"       åŒ¹é…æ ‡é¢˜: {result.matched_title[:50] if result.matched_title else 'N/A'}...")
        else:
            results_summary["not_found"] += 1
            print(f"    âŒ æœªæ‰¾åˆ°")

    print("\n" + "=" * 80)
    print("æµ‹è¯•æ€»ç»“")
    print("=" * 80)
    total = len(TEST_REFERENCES)
    print(f"æ€»æµ‹è¯•æ•°:       {total}")
    print(f"âœ… æ‰¾åˆ°:        {results_summary['found']} ({results_summary['found'] / total * 100:.1f}%)")
    print(f"âŒ æœªæ‰¾åˆ°:      {results_summary['not_found']} ({results_summary['not_found'] / total * 100:.1f}%)")
    print(f"\næŒ‰æ¥æºç»Ÿè®¡:")
    for source, count in results_summary["by_source"].items():
        if count > 0:
            print(f"  - {source}: {count}")
    print("=" * 80)


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="æµ‹è¯• Semantic Scholar æœç´¢èƒ½åŠ›ï¼ˆå«å™ªå£°æ ‡é¢˜ï¼‰")
    parser.add_argument(
        "--mode",
        choices=["raw", "full", "both"],
        default="both",
        help="æµ‹è¯•æ¨¡å¼: raw=åŸå§‹APIæœç´¢, full=å®Œæ•´æ£€æŸ¥å™¨, both=ä¸¤è€…éƒ½æµ‹"
    )

    args = parser.parse_args()

    if args.mode in ["raw", "both"]:
        test_semantic_scholar_raw_search()

    if args.mode in ["full", "both"]:
        test_full_checker()